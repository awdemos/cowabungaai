# End-to-end testing that deploys Supabase and the API, and deploy/tests llama-cpp-python, text-embeddings, and whisper

name: e2e-whisper
on:
  pull_request

concurrency:
  group: e2e-whisper-${{ github.ref }}
  cancel-in-progress: true

jobs:
  e2e_whisper:
    runs-on: ai-linux-x64-gpu

    permissions:
      contents: read
      packages: read
      id-token: write # This is needed for OIDC federation.

    steps:
        - name: Checkout Repo
          uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1

#        - name: Setup Python
#          uses: ./.github/actions/python
#          with:
#            additionalOptionalDep: dev-whisper

#        - name: Setup UDS Cluster
#          uses: ./.github/actions/uds-cluster
#          with:
#            registry1Username: ${{ secrets.IRON_BANK_ROBOT_USERNAME }}
#            registry1Password: ${{ secrets.IRON_BANK_ROBOT_PASSWORD }}
#            ghToken: ${{ secrets.GITHUB_TOKEN }}
#            chainguardIdentity: ${{ secrets.CHAINGUARD_IDENTITY }}
#
#        - name: Setup LFAI-API and Supabase
#          uses: ./.github/actions/lfai-core
#
#        ##########
#        # whisper
#        ##########
#        - name: Deploy whisper
#          run: |
#            make build-whisper LOCAL_VERSION=e2e-test
#            docker image prune -af
#            uds zarf package deploy packages/whisper/zarf-package-whisper-amd64-e2e-test.tar.zst -l=trace --confirm
#            rm packages/whisper/zarf-package-whisper-amd64-e2e-test.tar.zst

#        - name: Test whisper
#          run: |
#            python -m pytest ./tests/e2e/test_whisper.py -v

        - name: Test whisper
          run: |
            hostnamectl
            nvidia-smi
            nvcc --version
            kubectl config get-clusters
            kubectl config get-contexts
