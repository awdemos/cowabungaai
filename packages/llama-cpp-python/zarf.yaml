# yaml-language-server: $schema=https://raw.githubusercontent.com/uds-cli/uds-cli/v0.16.0/zarf.schema.json

kind: ZarfPackageConfig
metadata:
  name: llama-cpp-python
  version: "###ZARF_PKG_TMPL_IMAGE_VERSION###"
  description: >
    llama-cpp-python model

constants:
  - name: IMAGE_VERSION
    value: "###ZARF_PKG_TMPL_IMAGE_VERSION###"

variables:
  - name: PVC_SIZE
    description: Size of the PVC used for model storage.
    default: "15Gi"
    pattern: "^[0-9]+[a-zA-Z]+$"
  - name: PVC_ACCESS_MODE
    description: Access mode of the PVC used for model storage.
    default: "ReadWriteOnce"
    pattern: "^(ReadWriteOnce|ReadOnlyMany|ReadWriteMany)$"
  - name: PVC_STORAGE_CLASS
    description: Storage class of the PVC used for model storage.
    default: "local-path"

components:
  - name: llama-cpp-python-model
    required: true
    only:
      flavor: upstream
    charts:
      - name: llama-cpp-python-model
        namespace: leapfrogai
        localPath: chart
        releaseName: llama-cpp-python-model
        # x-release-please-start-version
        version: 0.14.0
        # x-release-please-end
        valuesFiles:
          - "values/upstream-values.yaml"
    images:
      - ghcr.io/defenseunicorns/leapfrogai/llama-cpp-python:###ZARF_PKG_TMPL_IMAGE_VERSION###
      - cgr.dev/chainguard/bash:latest
    dataInjections:
      - source: .model/
        target:
          namespace: leapfrogai
          selector: app=lfai-llama-cpp-python
          container: data-loader
          path: /data/.model
        compress: true
    actions:
      onCreate:
        before:
          # NOTE: This assumes python is installed and in $PATH and 'huggingface_hub[cli,hf_transfer]' has been installed
          - cmd: python scripts/model_download.py
            env:
              - REPO_ID=Qwen/Qwen2.5-Coder-7B-Instruct-GGUF
              - FILENAME=qwen2.5-coder-7b-instruct-q4_k_m.gguf
              - REVISION=main
              - SHA256_CHECKSUM=
